{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs / ConvNets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet architectures make the explicit assumption that the inputs are images. Each Layer in CNN accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function.\n",
    "\n",
    "Inputs : MNIST has images of width 28, height 28, and with 1 color channels Grey. In our case, number of filters is 32, size of filter is (3,3) and shape is (28,28,1).\n",
    "\n",
    "Convolutional Layer : This layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume.\n",
    "\n",
    "Activation Layer : This layer will apply an elementwise activation function. We used ReLU as Activation Layer, it the most popular one and eliminates vanishing gradient problem. ReLU function is f(x) = max(0, x), where x is the input. It sets all negative values in the matrix ‘x’ to 0 and keeps all the other values constant.  \n",
    "\n",
    "Pooling Layer : This layer will perform a downsampling operation along the spatial dimensions (width, height).It also reduces the number of parameters to learn, reducing the training time.\n",
    "\n",
    "Fully-Connected Layer (Dense layers ) : This layer will compute the final class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score. The last dense layer should be equal to the number of classes we want to predict as this is the output layer.\n",
    "\n",
    "BatchNormalization : This layer normalizes the matrix after it is been through a convolution layer so that the scale of each dimension remains the same. It reduces the training time significantly. It is used between Convolutional Layer and Activation Layer.\n",
    "\n",
    "Dropout : Method used to reduce overfitting. It forces the model to learn multiple independent representations of the same data by randomly disabling neurons in the learning phase.   \n",
    "\n",
    "Softmax Activation Layer : Softmax activation enables us to calculate the output based on the probabilities. Each class is assigned a probability and the class with the maximum probability is the model’s output for the input.\n",
    "\n",
    "categorical_crossentropy : calculates the error rate between the predicted value and the original value. Categorical is used because there are 10 classes to predict from. If there were 2 classes, we would have used binary_crossentropy.\n",
    "\n",
    "Adam Optimizer : The optimizer is responsible for updating the weights of the neurons via backpropagation. It calculates the derivative of the loss function with respect to each weight and subtracts it from the weight.\n",
    "    \n",
    "Tips\n",
    "    1. Final Total params should be as less as possible.\n",
    "    2. Use default stride of 1 or 2,3..for larger ones.\n",
    "    3. Padding not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ram/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ram/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Generic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "#Importing Keras Libraries\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "\n",
    "#Importing sklearn Libraries\n",
    "from sklearn import grid_search\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# There are 10 digits : 0..9\n",
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (60000, 28, 28))\n",
      "('y_train original shape', (60000,))\n",
      "('X_test original shape', (10000, 28, 28))\n",
      "('y_test original shape', (10000,))\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into Train and Test Sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Printing shape of the data set\\\n",
    "# input image dimensions : rows * cols = 28,28\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11838e810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1182cd2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying a sample training image\n",
    "plt.imshow(X_train[2], cmap='gray')\n",
    "plt.title('Class Object '+ str(y_train[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (60000, 28, 28, 1))\n",
      "('y_train original shape', (60000,))\n",
      "('X_test original shape', (10000, 28, 28, 1))\n",
      "('y_test original shape', (10000,))\n"
     ]
    }
   ],
   "source": [
    "#Normalization and reshaping of input\n",
    "#As images are in grayscale, the number of channels is 1. For color images, it's be 3 (R, G, B).\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#Rescaling so that each pixel lies in the interval [0, 1] instead of [0, 255]\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "#After normalizing the shape of data\\n,\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "#Before one-hot encoding\n",
    "print y_train[2]\n",
    "\n",
    "#After one-hot encoding\n",
    "print Y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model ():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    BatchNormalization()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Augmentation : Creating batches of images and train on them.\n",
    "# Tips for Data Augmentation : https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 177,322\n",
      "Trainable params: 177,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "937/937 [==============================] - 238s - loss: 0.8385 - acc: 0.7246 - val_loss: 0.0761 - val_acc: 0.9782\n",
      "Epoch 2/8\n",
      "937/937 [==============================] - 253s - loss: 0.3028 - acc: 0.9194 - val_loss: 0.0439 - val_acc: 0.9872\n",
      "Epoch 3/8\n",
      "937/937 [==============================] - 262s - loss: 0.2305 - acc: 0.9394 - val_loss: 0.0426 - val_acc: 0.9887\n",
      "Epoch 4/8\n",
      "937/937 [==============================] - 265s - loss: 0.2023 - acc: 0.9478 - val_loss: 0.0298 - val_acc: 0.9920\n",
      "Epoch 5/8\n",
      "937/937 [==============================] - 257s - loss: 0.1823 - acc: 0.9529 - val_loss: 0.0315 - val_acc: 0.9923\n",
      "Epoch 6/8\n",
      "937/937 [==============================] - 272s - loss: 0.1599 - acc: 0.9580 - val_loss: 0.0239 - val_acc: 0.9938\n",
      "Epoch 7/8\n",
      "937/937 [==============================] - 232s - loss: 0.1528 - acc: 0.9612 - val_loss: 0.0288 - val_acc: 0.9932\n",
      "Epoch 8/8\n",
      "937/937 [==============================] - 202s - loss: 0.1457 - acc: 0.9626 - val_loss: 0.0325 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118363d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating model and fitting\n",
    "model = create_model()\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=8,\n",
    "                    validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s('Test accuracy: ', 0.029497148081474005)\n",
      "('Test accuracy: ', 0.99299999999999999)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Model,\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#Making Predictions, Comparing Actuals to Predictions and writing to a file\n",
    "predictions = model.predict_classes(X_test)\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "sub.to_csv('./op_mnist_cnn.csv', index=False)\n",
    "\n",
    "#Metrics\n",
    "#Refer : https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
